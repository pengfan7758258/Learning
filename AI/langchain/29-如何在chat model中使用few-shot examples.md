- [åœ°å€](https://python.langchain.com/docs/how_to/few_shot_examples_chat/)

## fix examples
<mark style="background: #FFB86CA6;">examples:</mark>
```python
examples = [  
	{"input": "2 ğŸ¦œ 2", "output": "4"},  
	{"input": "2 ğŸ¦œ 3", "output": "5"},  
]
```
<mark style="background: #FFB86CA6;">ç»„åˆfew-shotï¼š</mark>
- example_promptï¼šé€šè¿‡å…¶Â `format_messages`Â æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸º 1 ä¸ªæˆ–å¤šä¸ªæ¶ˆæ¯
- few_shot_promptï¼šä½¿ç”¨`FewShotChatMessagePromptTemplate`æ•´åˆexample_promptæ¨¡ç‰ˆæ¥ç”Ÿæˆ few-shot messages
```python
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

example_prompt = ChatPromptTemplate.from_messages(  
	[  
		("human", "{input}"),  
		("ai", "{output}") 
	]  
)
# å°†examplesæ•°æ®å¡«å……åˆ°example_prompt
few_shot_prompt = FewShotChatMessagePromptTemplate(  
	example_prompt=example_prompt, # å¡«å……æ¨¡ç‰ˆ 
	examples=examples # æ ·ä¾‹æ•°æ®
)
print(few_shot_prompt.invoke({}).to_messages())
"""
------------- output -------------
[HumanMessage(content='2 ğŸ¦œ 2', additional_kwargs={}, response_metadata={}), 
AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 ğŸ¦œ 3', additional_kwargs={}, response_metadata={}), 
AIMessage(content='5', additional_kwargs={}, response_metadata={})]
"""
```
<mark style="background: #FFB86CA6;">final_promptå¹¶è°ƒç”¨modelï¼š</mark>
```python

final_prompt = ChatPromptTemplate.from_messages(
Â  Â  [
Â  Â  Â  Â  ("system", "You are a wondrous wizard of math."),
Â  Â  Â  Â  few_shot_prompt,
Â  Â  Â  Â  ("human", "{input}"),
Â  Â  ]
)

from langchain.chat_models import init_chat_model
# åŠ è½½æ¨¡å‹
model = init_chat_model(
Â  Â  model="gpt-4o-mini",
Â  Â  model_provider="openai"
)

chain = final_prompt | model
chain.invoke({"input": "9 ğŸ¦œ 2"})
"""
--------- output ----------
AIMessage(content='11', additional_kwargs=...)

æ¨¡å‹ä»ç»™å®šçš„å°‘é‡ç¤ºä¾‹ä¸­æ¨æ–­å‡ºé¹¦é¹‰è¡¨æƒ…ç¬¦å·ä»£è¡¨åŠ æ³•ï¼
"""
```
## dynamic examples
<mark style="background: #FFB86CA6;">vectorstoreï¼š</mark>
```python
from langchain_community.vectorstores import FAISS
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings

examples = [
    {"input": "2 ğŸ¦œ 2", "output": "4"},
    {"input": "2 ğŸ¦œ 3", "output": "5"},
    {"input": "2 ğŸ¦œ 4", "output": "6"},
    {"input": "What did the cow say to the moon?", "output": "nothing at all"},
    {
        "input": "Write me a poem about the moon",
        "output": "One for the moon, and one for me, who are we to talk about the moon?",
    },
]

to_vectorize = [" ".join(example.values()) for example in examples]
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(to_vectorize, embeddings, metadatas=examples)
```
<mark style="background: #FFB86CA6;">create  example_selectorï¼š</mark>
```python
example_selector = SemanticSimilarityExampleSelector(
    vectorstore=vectorstore,
    k=2,
)
example_selector.select_examples({"input": "horse"})
"""
------------ output ---------------
[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},
 {'input': '2 ğŸ¦œ 4', 'output': '6'}]
"""
```
<mark style="background: #FFB86CA6;">Create prompt templateï¼š</mark>
```python
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# å®šä¹‰few-shot prompt tempalte.
few_shot_prompt = FewShotChatMessagePromptTemplate(
    # é€‰æ‹©å™¨è¾“å…¥å˜é‡ input key
    input_variables=["input"],
    example_selector=example_selector,
    example_prompt=ChatPromptTemplate.from_messages(
        [("human", "{input}"), ("ai", "{output}")]
    ),
)

print(few_shot_prompt.invoke(input="What's 3 ğŸ¦œ 3?").to_messages())
"""
---------------- output ----------------
[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]
"""
```
<mark style="background: #FFB86CA6;">final_promptå¹¶è°ƒç”¨modelï¼š</mark>
```python
final_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a wondrous wizard of math."),
        few_shot_prompt,
        ("human", "{input}"),
    ]
)

print(few_shot_prompt.invoke(input="What's 3 ğŸ¦œ 3?"))
"""
------------- output -----------------
messages=[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]
"""

chain = final_prompt | model
chain.invoke({"input": "What's 9 ğŸ¦œ 2?"})

"""
--------- output ----------
AIMessage(content='11', additional_kwargs=...)

æ¨¡å‹ä»ç»™å®šçš„å°‘é‡ç¤ºä¾‹ä¸­æ¨æ–­å‡ºé¹¦é¹‰è¡¨æƒ…ç¬¦å·ä»£è¡¨åŠ æ³•ï¼
"""
""""
```