**项目名称**：minimind
**项目目标**：从0训练26M的小参数GPT！
**项目地址**：https://github.com/jingyaogong/minimind

**项目包含：**
1. Pretrain、SFT指令微调、LoRA微调、DPO偏好优化的全过程代码、数据集和来源
2. 兼容transformers、accelerate、trl、peft等流行框架
3. 训练支持单机单卡、单机多卡(DDP、DeepSpeed)训练，使用wandb可视化训练流程。支持在任意位置停止，及在任意位置继续训练。
4. 在c-eval数据集上进行模型测试的代码
5. 实现Openai-Api基本的chat接口，便于集成到第三方ChatUI使用（FastGPT、Open-WebUI等）

**没做完的原因：训练框架很多，这个适合来看底层，但是真实训练可以选择更简单，更好的方式**